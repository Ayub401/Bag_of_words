{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPQLC8sugA9E"
   },
   "source": [
    "# Implementing Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qHuB7gLgA9F"
   },
   "source": [
    "<font face='georgia'>\n",
    "    <h3><strong>Fit method:</strong></h3>\n",
    "\n",
    "<ol>\n",
    "    <li> With this function, we will find all unique words in the data and we will assign a dimension-number to each unique word. </li>\n",
    "    <br>\n",
    "    <li> We  will create a python dictionary to save all the unique words, such that the key of dictionary represents a unique word and the corresponding value represent it's dimension-number. </li><br>\n",
    "    <li> For example, if you have a review, <strong>__'very bad pizza'__</strong> then you can represent each unique word with a dimension_number as, <br>\n",
    "        <strong>dict</strong> = { 'very' : 1, 'bad' : 2, 'pizza' : 3}     </li>\n",
    "    </ol>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vmQOru_LgA9F"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vWqqbym-gA9I"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm # tqdm is a library that helps us to visualize the runtime of for loop. refer this to know more about tqdm\n",
    "#https://tqdm.github.io/\n",
    "\n",
    "# it accepts only list of sentances\n",
    "def fit(dataset):    \n",
    "    unique_words = set() # at first we will initialize an empty set\n",
    "    # check if its list type or not\n",
    "    if isinstance(dataset, (list,)):\n",
    "        for row in dataset: # for each review in the dataset\n",
    "            for word in row.split(\" \"): # for each word in the review. #split method converts a string into list of words\n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                unique_words.add(word)\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "        #print(unique_words)    \n",
    "        return vocab\n",
    "    else:\n",
    "        print(\"you need to pass list of sentance\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooIF0xaugA9J",
    "outputId": "96ed6914-5a0a-4b96-ba70-e7af858aed9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aaa': 0, 'aaaaaaa': 1, 'abbb': 2, 'abc': 3, 'baaa': 4, 'def': 5, 'lmn': 6, 'pqr': 7, 'prq': 8}\n"
     ]
    }
   ],
   "source": [
    "datset = [\"abc def aaa prq\", \"lmn pqr aaaaaaa aaa abbb baaa\"]\n",
    "vocab = fit(datset)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtHD5uKWgA9N"
   },
   "source": [
    "<font face='georgia'>\n",
    "    <h4><strong>What is a Sparse Matrix?</strong></h4>\n",
    "\n",
    "<ol>\n",
    "    <li>Before going further into details about Transform method, we will understand what sparse matrix is.</li>\n",
    "    <br>\n",
    "    <li> Sparse matrix stores only non-zero elements and they occupy less amount of RAM comapre to a dense matrix. You can refer to this <a href=\"http://btechsmartclass.com/data_structures/sparse-matrix.html\"><u>link</u>.</a> </li><br>\n",
    "    <li> For example, assume you have a matrix,\n",
    "        <pre>\n",
    "[[1, 0, 0, 0, 0], \n",
    "[0, 0, 0, 1, 0], \n",
    "[0, 0, 4, 0, 0]] \n",
    "</pre>   </li>\n",
    "    </ol>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khrRTJ-qgA9N",
    "outputId": "9f1e3a4f-0d41-4a3f-923a-e50db80abc99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes 240\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof  # will tell amount of memory occupied.\n",
    "import numpy as np\n",
    "# we store every element here\n",
    "a = np.array([[1, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 4, 0, 0]])\n",
    "print(\"Bytes\",getsizeof(a))\n",
    "\n",
    "# here we are storing only non zero elements here (row, col, value)\n",
    "a = [ (0, 0, 1), (1, 3, 1), (2,2,4)]  # (raw,column,value). pass list of tuple \n",
    "# with this way of storing we are saving alomost 50% memory for this example\n",
    "print(getsizeof(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2Nm850wgA9Q"
   },
   "source": [
    "<font face='georgia'>\n",
    "    <h4><strong>How to write a Sparse Matrix?:</strong></h4>\n",
    "\n",
    "<ol>\n",
    "    <li> You can use csr_matrix() method of scipy.sparse to write a sparse matrix.</li>\n",
    "    <li> You need to pass indices of non-zero elements into csr_matrix() for creating a sparse matrix. </li>\n",
    "    <li> You also need to pass element value of each pair of indices. </li>\n",
    "    <li> You can use lists to save the indices of non-zero elements and their corresponding element values. </li>\n",
    "    <li> For example, \n",
    "        <ul>\n",
    "            <li>Assume you have a matrix,\n",
    "        <pre>\n",
    "    [[1, 0, 0], \n",
    "    [0, 0, 1], \n",
    "    [4, 0, 6]] \n",
    "    </pre></li>\n",
    "        <li> Then you can save the indices using a list as,<br><strong>list_of_indices</strong> =  [(0,0), (1,2), (2,0), (2,2)]</li>\n",
    "            <li> And you can save the corresponding element values as, <br><strong>element_values</strong> = [1, 1, 4, 6]  </li>\n",
    "        </ul></li>\n",
    "    <li> Further you can refer to the documentation  <a href=\"https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.sparse.csr_matrix.html\"><u>here</u>.</a> </li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yU_D0uyFmv5W",
    "outputId": "d2e5ec98-55fe-4ec1-8058-daaaf1d63dae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example from web\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "csr_matrix((3, 4), dtype=np.int8).toarray()     # 3 raw and 4 column.\n",
    "\n",
    "# the output will contain a 3*4 null matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loy3FJDEnMSu",
    "outputId": "622eb87a-257a-4c43-e7cb-03ac16345442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "X = csr_matrix((3, 4), dtype=np.int32)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKAUEhgLn8Jr",
    "outputId": "0687dc93-2b82-4df8-8337-b1a631dfc52c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1jHXKjYosbj",
    "outputId": "4470dad1-cdca-490f-82df-7f583ba68c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2]\n",
      " [0 0 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "row = np.array([0, 0, 1, 2, 2, 2])  #row position\n",
    "col = np.array([0, 2, 2, 0, 1, 2])  #column position\n",
    "data = np.array([1, 2, 3, 4, 5, 6]) #corresponding element in the matrix.\n",
    "\n",
    "# at (0,0) the element stored is 1.\n",
    "Matrix = csr_matrix((data, (row, col)), shape=(3, 3)).toarray()  # it will create a 3*3 matrix.\n",
    "print(Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-9bBAPMp8vz",
    "outputId": "8e7c521c-4dca-447d-f856-3d7d6017cc01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "print(getsizeof(Matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S57yXfGSgA9Q"
   },
   "source": [
    "<font face='georgia'>\n",
    "    <h3><strong>Transform method:</strong></h3>\n",
    "\n",
    "<ol>\n",
    "    <li>With this function, we will write a feature matrix using sprase matrix.</li>\n",
    "    </ol>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwcUnNKsgA9R",
    "outputId": "fb52ca36-8d60-40b1-b1e5-8f1bd212f202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABC': 3, 'def': 2, 'zzz': 2, 'pqr': 1, 'abc': 1}\n",
      "<class 'dict'>\n",
      "ABC 3\n",
      "def 2\n",
      "zzz 2\n",
      "pqr 1\n",
      "abc 1\n"
     ]
    }
   ],
   "source": [
    "#example from web\n",
    "from collections import Counter   \n",
    "#https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "'''A Counter is a dict subclass for counting hashable objects. It is a collection where \n",
    "elements are stored as dictionary keys and their counts are stored as dictionary values. \n",
    "Counts are allowed to be any integer value including zero or negative counts. \n",
    "The Counter class is similar to bags or multisets in other languages.'''\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "test = 'ABC def ABC def zzz zzz pqr ABC abc'\n",
    "a = dict(Counter(test.split()))     # will compute the frequency and store in the dict as value.\n",
    "print(a)\n",
    "print(type(a))  #note this \n",
    "for i,j in a.items():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8tAs7552xRW",
    "outputId": "a9effd5c-c868-438e-d8ec-e14d47656334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 5), ('b', 2), ('r', 2)]\n",
      "[('a', 5), ('b', 2), ('r', 2), ('c', 1), ('d', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter('abracadabra').most_common(3))\n",
    "Z = Counter('abracadabra').most_common()\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJCAy7t4kY1L",
    "outputId": "0c8cc48f-d88b-4fcd-aa49-f8c2160dd17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ABC': 3, 'def': 2, 'zzz': 2, 'pqr': 1, 'abc': 1})\n",
      "<class 'collections.Counter'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "test = 'ABC def ABC def zzz zzz pqr ABC abc'\n",
    "C = Counter(test.split())  # will return a python dictionary\n",
    "print(C)\n",
    "print(type(C))      #match with above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5NC4NIz1o9T",
    "outputId": "c2338153-a5d6-43ce-cedb-53981c7a45a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aaa': 0, 'aaaaaaa': 1, 'abbb': 2, 'abc': 3, 'baaa': 4, 'def': 5, 'lmn': 6, 'pqr': 7, 'prq': 8}\n"
     ]
    }
   ],
   "source": [
    "datset = [\"abc def aaa prq\", \"lmn pqr aaaaaaa aaa abbb baaa\"]\n",
    "vocab = fit(datset)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Q-YjuuVHgA9T"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/9919604/efficiently-calculate-word-frequency-in-a-string\n",
    "# https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.sparse.csr_matrix.html\n",
    "# note that we are we need to send the preprocessing text here, we have not inlcuded the processing\n",
    "\n",
    "def transform(dataset,vocab):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, (list,)):\n",
    "        for idx, row in enumerate((dataset)): # for each review in the dataset\n",
    "        #idx will be either 0 or 1 as the dataset is 2*2 matrix.\n",
    "            # it will return a dict type object where key is the word and values is its frequency, {word:frequency}\n",
    "            word_freq = dict(Counter(row.split())) #dic to first review in iteration one.\n",
    "            print(\"The word frequency are \",word_freq) \n",
    "            # for every unique word in the document\n",
    "            for word, freq in word_freq.items():  # for each unique word in the review.                \n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                # we will check if its there in the vocabulary that we build in fit() function\n",
    "                # dict.get() function will return the values/actually column index, if the key doesn't exits it will return -1\n",
    "                col_index = vocab.get(word, -1) # will return the values/actully columns\n",
    "                # if the word exists\n",
    "                if col_index !=-1:\n",
    "                    # we are storing the index of the document\n",
    "                    rows.append(idx)\n",
    "                    # we are storing the dimensions of the word\n",
    "                    columns.append(col_index)\n",
    "                    # we are storing the frequency of the word\n",
    "                    values.append(freq)\n",
    "                    \n",
    "        print(\"the row index are:    \",rows)\n",
    "        print(\"the column index are: \",columns)\n",
    "        print(\"the values are:       \",values) \n",
    "        print(\"The tranformed matrix is \")\n",
    "        return csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab)))\n",
    "    else:\n",
    "        print(\"you need to pass list of strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jD4RmMoAJ38",
    "outputId": "77ad8ff7-7bd3-4d0c-e7bd-3e8fd0b46e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values in dictionary canbe used as colmn indx {'This': 0, 'but': 1, 'cheap': 2, 'delecious': 3, 'is': 4, 'pasta': 5, 'testy': 6, 'very': 7}\n",
      "******************************\n",
      "The word frequency are  {'This': 1, 'pasta': 1, 'is': 1, 'very': 2, 'testy': 1}\n",
      "The word frequency are  {'This': 1, 'pasta': 2, 'is': 1, 'cheap': 1, 'but': 1, 'delecious': 1}\n",
      "the row index are:     [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "the column index are:  [0, 5, 4, 7, 6, 0, 5, 4, 2, 1, 3]\n",
      "the values are:        [1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1]\n",
      "The tranformed matrix is \n",
      "[[1 0 0 0 1 1 1 2]\n",
      " [1 1 1 1 1 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "Review1 = \"This pasta is very very testy\"\n",
    "Review2 = \"This pasta is cheap but delecious pasta\"\n",
    "Text = [Review1,Review2]\n",
    "vocab = fit(Text)\n",
    "print(\"values in dictionary canbe used as colmn indx\",vocab)\n",
    "print(\"*\"*30)\n",
    "\n",
    "print(transform(Text, vocab).toarray())\n",
    "\n",
    "#first raw for first review.\n",
    "#second raw for the secons review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uE2MnZMC3WJ",
    "outputId": "cd0de8c2-83b3-4ffa-c3a0-fd50da90b060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 1 1 2]\n",
      " [1 1 1 1 2 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "vec.fit(Text)\n",
    "feature_matrix_2 = vec.transform(Text)\n",
    "print(feature_matrix_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7EpT6qngA9V",
    "outputId": "0eba75aa-9e7b-489f-e2eb-193a466837f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['but', 'centerpiece', 'economic', 'economists', 'for', 'is', 'its', 'lagrange', 'method', 'multipliers', 'of', 'optimization', 'poorly', 'problems', 'solving', 'taught', 'technique', 'the', 'theory', 'unfortunately', 'usually', 'workhorse']\n",
      "The word frequency are  {'the': 2, 'method': 1, 'of': 1, 'lagrange': 1, 'multipliers': 1, 'is': 1, 'economists': 1, 'workhorse': 1, 'for': 1, 'solving': 1, 'optimization': 1, 'problems': 1}\n",
      "The word frequency are  {'the': 1, 'technique': 1, 'is': 1, 'a': 1, 'centerpiece': 1, 'of': 1, 'economic': 1, 'theory': 1, 'but': 1, 'unfortunately': 1, 'its': 1, 'usually': 1, 'taught': 1, 'poorly': 1}\n",
      "the row index are:     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "the column index are:  [17, 8, 10, 7, 9, 5, 3, 21, 4, 14, 11, 13, 17, 16, 5, 1, 10, 2, 18, 0, 19, 6, 20, 15, 12]\n",
      "the values are:        [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "The tranformed matrix is \n",
      "[[0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 2 0 0 0 1]\n",
      " [1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "strings = [\"the method of lagrange multipliers is the economists workhorse for solving optimization problems\",\n",
    "           \"the technique is a centerpiece of economic theory but unfortunately its usually taught poorly\"]\n",
    "vocab = fit(strings)\n",
    "print(list(vocab.keys()))\n",
    "print(transform(strings, vocab).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0ZpSe7fgA9Y"
   },
   "source": [
    "## Comparing results with countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6E8InIJgA9Z",
    "outputId": "14b87ec9-ea49-4f56-a936-88c551e73419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 2 0 0 0 1]\n",
      " [1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(analyzer='word')\n",
    "\n",
    "vec.fit(strings)\n",
    "feature_matrix_2 = vec.transform(strings)\n",
    "print(feature_matrix_2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2fhGpemOYt-",
    "outputId": "53fcb2a2-7452-4e4e-81e4-436b88da8f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values in dictionary canbe used as colmn indx {'This': 0, 'but': 1, 'cheap': 2, 'delecious': 3, 'is': 4, 'pasta': 5, 'testy': 6, 'very': 7}\n",
      "******************************\n",
      "The word frequency are  {'This': 1, 'pasta': 1, 'is': 1, 'very': 2, 'testy': 1}\n",
      "The word frequency are  {'This': 1, 'pasta': 2, 'is': 1, 'cheap': 1, 'but': 1, 'delecious': 1}\n",
      "the row index are:     [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "the column index are:  [0, 5, 4, 7, 6, 0, 5, 4, 2, 1, 3]\n",
      "the values are:        [1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1]\n",
      "The tranformed matrix is \n",
      "[[1 0 0 0 1 1 1 2]\n",
      " [1 1 1 1 1 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def fit(dataset):    \n",
    "    unique_words = set()  \n",
    "    if isinstance(dataset, (list,)):\n",
    "        for row in dataset: \n",
    "            for word in row.split(\" \"):\n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                unique_words.add(word)\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "        #print(unique_words)    \n",
    "        return vocab\n",
    "    else:\n",
    "        print(\"you need to pass list of sentance\")\n",
    "\n",
    "def transform(dataset,vocab):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, (list,)):\n",
    "        for idx, row in enumerate((dataset)):  \n",
    "            word_freq = dict(Counter(row.split())) \n",
    "            print(\"The word frequency are \",word_freq) \n",
    "            for word, freq in word_freq.items():  \n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                col_index = vocab.get(word, -1) \n",
    "                if col_index !=-1:  \n",
    "                    rows.append(idx)\n",
    "                    columns.append(col_index)\n",
    "                    values.append(freq)            \n",
    "        print(\"the row index are:    \",rows)\n",
    "        print(\"the column index are: \",columns)\n",
    "        print(\"the values are:       \",values) \n",
    "        print(\"The tranformed matrix is \")\n",
    "        return csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab)))\n",
    "    else:\n",
    "        print(\"you need to pass list of strings\")\n",
    "\n",
    "#Calling the function\n",
    "Review1 = \"This pasta is very very testy\"\n",
    "Review2 = \"This pasta is cheap but delecious pasta\"\n",
    "Text = [Review1,Review2]\n",
    "vocab = fit(Text)\n",
    "print(\"values in dictionary canbe used as colmn indx\",vocab)\n",
    "print(\"*\"*30)\n",
    "\n",
    "print(transform(Text, vocab).toarray())       "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bag_of_words.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
